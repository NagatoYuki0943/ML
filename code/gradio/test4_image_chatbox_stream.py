# å¯¼å…¥å¿…è¦çš„åº“
import gradio as gr
import numpy as np
from typing import Generator, Sequence
import threading
import time
from PIL import Image
from loguru import logger
import hashlib


logger.info(f"gradio version: {gr.__version__}")


class InterFace:
    global_session_id: int = 0
    lock = threading.Lock()


def hash_image(image: Image.Image) -> str:
    md5 = hashlib.md5()
    md5.update(image.tobytes())
    return md5.hexdigest()


def chat_stream_with_image(
    query: str,
    history: Sequence | None = None,  # [['What is the capital of France?', 'The capital of France is Paris.'], ['Thanks', 'You are Welcome']]
    max_new_tokens: int = 1024,
    temperature: float = 0.8,
    top_p: float = 0.8,
    top_k: int = 40,
    image: Image.Image | None = None,
    current_img: str = "",
    state_session_id: int = 0,
) -> Generator[tuple[Sequence, Image.Image], None, None]:
    history = [] if history is None else list(history)

    logger.info(f"{state_session_id = }")

    query = query.strip()
    if query == None or len(query) < 1:
        yield history, current_img
        return

    logger.info({
            "max_new_tokens":  max_new_tokens,
            "temperature": temperature,
            "top_p": top_p,
            "top_k": top_k,
    })

    logger.info(f"{image = }")
    logger.info(f"{current_img = }")
    if isinstance(image, Image.Image):
        new_img_hash = hash_image(image)
        logger.info(f"{new_img_hash = }")

        # æ–°å›¾ç‰‡
        if new_img_hash != current_img:
            logger.warning(f"update image hash")
            logger.info({
                "height": image.height,
                "width": image.width,
                "mode": image.mode
            })
            # è½¬æ¢RGB2BGR
            # image = Image.fromarray(np.array(image)[..., ::-1])
            current_img = new_img_hash
        else:
            # å›¾ç‰‡å’Œä¹‹å‰ç›¸åŒè®¾ç½®ä¸º None
            image = None
    else:
        # ä¸æ˜¯ PIL.Image.Image è®¾ç½®ä¸º None
        image = None
    logger.info(f"updated image: {image}")

    logger.info(f"query: {query}")
    number: np.ndarray = np.random.randint(1, 100, 20)
    for i in range(len(number)):
        time.sleep(0.1)
        logger.info(number[i])
        yield history + [[query, str(number[:i+1])]], current_img
        # åœ¨èŠå¤©è®°å½•ä¸­æ˜¾ç¤ºå›¾ç‰‡,éœ€è¦æ˜¯å›¾ç‰‡url,ä¸èƒ½æ˜¯ image å¯¹è±¡
        # yield history + [[("image url",), None], [query, str(number[:i+1])]], image
    logger.info(f"response: {number}")


"""regenerate å’Œ revocery åœ¨ä½¿ç”¨å›¾ç‰‡å’Œæ–‡å­—æ—¶ä¼šå‡ºç°é—®é¢˜
å‡è®¾ä¸€ä¸‹å†å²è®°å½•
    [
        [queston1, answer1], # use image
    ]
    image
åœ¨åªæœ‰ä¸€è½®å¯¹è¯çš„æƒ…å†µä¸‹,regenerate éœ€è¦ä½¿ç”¨å›¾ç‰‡å’Œé—®é¢˜, recovery éœ€è¦ä¸¢å¼ƒä¸Šä¸€è½®çš„å›ç­”å’Œå›¾ç‰‡

ä½†æ˜¯åœ¨æœ‰å¤šè½®å¯¹è¯,ä¸”ä¸Šä¸€è½®å¯¹è¯æ²¡ç”¨åˆ°å›¾ç‰‡çš„æƒ…å†µä¸‹
    [
        [queston1, answer1], # not use image
        [queston2, answer2], # use image
    ]
    image
regenerate ä¸éœ€è¦ä½¿ç”¨å›¾ç‰‡,ä½†æ˜¯æˆ‘ä¸çŸ¥é“ä¸Šä¸€è½®æ˜¯å¦ä½¿ç”¨äº†å›¾ç‰‡, recovery éœ€è¦ä¸¢å¼ƒä¸Šä¸€è½®çš„å›ç­”,å•ä¸éœ€è¦ä¸¢å¼ƒå›¾ç‰‡
"""

def regenerate(
    query: str,
    history: Sequence | None = None,  # [['What is the capital of France?', 'The capital of France is Paris.'], ['Thanks', 'You are Welcome']]
    max_new_tokens: int = 1024,
    temperature: float = 0.8,
    top_p: float = 0.8,
    top_k: int = 40,
    image: Image.Image | None = None,
    current_img: str = "",
    state_session_id: int = 0,
) -> Generator[tuple[Sequence, Image.Image], None, None]:
    history = [] if history is None else list(history)

    # é‡æ–°ç”Ÿæˆæ—¶è¦æŠŠæœ€åçš„queryå’Œresponseå¼¹å‡º,é‡ç”¨query
    if len(history) > 0:
        query, _ = history.pop(-1)
        yield from chat_stream_with_image(
            query = query,
            history = history,
            max_new_tokens = max_new_tokens,
            temperature = temperature,
            top_p = top_p,
            top_k = top_k,
            image = image,
            current_img = current_img,
            state_session_id = state_session_id,
        )
    else:
        yield history, image


def revocery(history: Sequence | None = None) -> tuple[str, Sequence]:
    """æ¢å¤åˆ°ä¸Šä¸€è½®å¯¹è¯"""
    history = [] if history is None else list(history)
    query = ""
    if len(history) > 0:
        query, _ = history.pop(-1)
    return query, history


def main():
    block = gr.Blocks()
    with block as demo:
        state_session_id = gr.State(0)

        with gr.Row(equal_height=True):
            with gr.Column(scale=15):
                gr.Markdown("""<h1><center>ğŸ¦™ LLaMA 3</center></h1>
                    <center>ğŸ¦™ LLaMA 3 Chatbot ğŸ’¬</center>
                    """)
            # gr.Image(value=LOGO_PATH, scale=1, min_width=10,show_label=False, show_download_button=False)

        with gr.Row():
            with gr.Column(scale=4):
                with gr.Row():
                    # ç”¨æ¥å­˜æ”¾ocrå›¾ç‰‡è·¯å¾„ï¼Œé˜²æ­¢é‡å¤ä½¿ç”¨ocr
                    current_img = gr.State("")
                    image = gr.Image(sources=["upload", "webcam", "clipboard"], image_mode="RGB", type="pil", interactive=True)

                    with gr.Column(scale=2):
                        # åˆ›å»ºèŠå¤©æ¡†
                        chatbot = gr.Chatbot(height=500, show_copy_button=True, placeholder="å†…å®¹ç”± AI å¤§æ¨¡å‹ç”Ÿæˆï¼Œè¯·ä»”ç»†ç”„åˆ«ã€‚")

                # ç»„å†…çš„ç»„ä»¶æ²¡æœ‰é—´è·
                with gr.Group():
                    with gr.Row():
                        # åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡†ç»„ä»¶ï¼Œç”¨äºè¾“å…¥ promptã€‚
                        query = gr.Textbox(
                            lines=1,
                            label="Prompt / é—®é¢˜",
                            placeholder="Enter å‘é€; Shift + Enter æ¢è¡Œ / Enter to send; Shift + Enter to wrap"
                        )
                        # åˆ›å»ºæäº¤æŒ‰é’®ã€‚
                        # variant https://www.gradio.app/docs/button
                        # scale https://www.gradio.app/guides/controlling-layout
                        submit = gr.Button("ğŸ’¬ Chat", variant="primary", scale=0)

                gr.Examples(
                    examples=[
                        ["ä½ æ˜¯è°"],
                        ["ä½ å¯ä»¥å¸®æˆ‘åšä»€ä¹ˆ"],
                    ],
                    inputs=[query],
                    label="ç¤ºä¾‹é—®é¢˜ / Example questions"
                )

                with gr.Row():
                    # åˆ›å»ºä¸€ä¸ªé‡æ–°ç”ŸæˆæŒ‰é’®ï¼Œç”¨äºé‡æ–°ç”Ÿæˆå½“å‰å¯¹è¯å†…å®¹ã€‚
                    regen = gr.Button("ğŸ”„ Retry", variant="secondary")
                    undo = gr.Button("â†©ï¸ Undo", variant="secondary")
                    # åˆ›å»ºä¸€ä¸ªæ¸…é™¤æŒ‰é’®ï¼Œç”¨äºæ¸…é™¤èŠå¤©æœºå™¨äººç»„ä»¶çš„å†…å®¹ã€‚
                    clear = gr.ClearButton(components=[chatbot, image, current_img], value="ğŸ—‘ï¸ Clear", variant="stop")

                # æŠ˜å 
                with gr.Accordion("Advanced Options", open=False):
                    with gr.Row():
                        max_new_tokens = gr.Slider(
                            minimum=1,
                            maximum=2048,
                            value=1024,
                            step=1,
                            label='Max new tokens'
                        )
                        temperature = gr.Slider(
                            minimum=0.01,
                            maximum=2,
                            value=0.8,
                            step=0.01,
                            label='Temperature'
                        )
                        top_p = gr.Slider(
                            minimum=0.01,
                            maximum=1,
                            value=0.8,
                            step=0.01,
                            label='Top_p'
                        )
                        top_k = gr.Slider(
                            minimum=1,
                            maximum=100,
                            value=40,
                            step=1,
                            label='Top_k'
                        )

            # å›è½¦æäº¤
            query.submit(
                chat_stream_with_image,
                inputs=[query, chatbot, max_new_tokens, temperature, top_p, top_k, image, current_img, state_session_id],
                outputs=[chatbot, current_img]
            )

            # æ¸…ç©ºquery
            query.submit(
                lambda: gr.Textbox(value=""),
                [],
                [query],
            )

            # æŒ‰é’®æäº¤
            submit.click(
                chat_stream_with_image,
                inputs=[query, chatbot, max_new_tokens, temperature, top_p, top_k, image, current_img, state_session_id],
                outputs=[chatbot, current_img]
            )

            # æ¸…ç©ºquery
            submit.click(
                lambda: gr.Textbox(value=""),
                [],
                [query],
            )

            # é‡æ–°ç”Ÿæˆ
            regen.click(
                regenerate,
                inputs=[query, chatbot, max_new_tokens, temperature, top_p, top_k, image, current_img, state_session_id],
                outputs=[chatbot, current_img]
            )

            # æ’¤é”€
            undo.click(
                revocery,
                inputs=[chatbot],
                outputs=[query, chatbot]
            )

        gr.Markdown("""æé†’ï¼š<br>
        1. å†…å®¹ç”± AI å¤§æ¨¡å‹ç”Ÿæˆï¼Œè¯·ä»”ç»†ç”„åˆ«ã€‚<br>
        """)

        # åˆå§‹åŒ–session_id
        def init():
            with InterFace.lock:
                InterFace.global_session_id += 1
            new_session_id = InterFace.global_session_id
            return new_session_id

        demo.load(init, inputs=None, outputs=[state_session_id])

    # threads to consume the request
    gr.close_all()

    # è®¾ç½®é˜Ÿåˆ—å¯åŠ¨
    demo.queue(
        max_size = None,                # If None, the queue size will be unlimited.
        default_concurrency_limit = 100 # æœ€å¤§å¹¶å‘é™åˆ¶
    )

    # demo.launch(server_name = "127.0.0.1", server_port = 7860, share = True, max_threads = 100)
    demo.launch(max_threads = 100)


if __name__ == "__main__":
    main()
